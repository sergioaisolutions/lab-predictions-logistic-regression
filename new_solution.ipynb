{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h2>IMPORTING THE REQUIRED LIBRARIES</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from getpass import getpass\r\n",
    "from mysql.connector import connection\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\r\n",
    "from imblearn.over_sampling import SMOTE\r\n",
    "\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\r\n",
    "\r\n",
    "pd.set_option('display.max_columns', None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>CREATING A CONNECTION BETWEEN OUR JUPYTER NOTEBOOK AND MYSQL. SELECTING THE SAKILA DATABASE</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def mysql_database_connection(user, host, database):\r\n",
    "\r\n",
    "    password = getpass()\r\n",
    "\r\n",
    "    mysql_connection = connection.MySQLConnection(user = user, password = password,\r\n",
    "                                                  host = host, database = database)\r\n",
    "                                     \r\n",
    "    return mysql_connection\r\n",
    "\r\n",
    "sakila_engine = mysql_database_connection('root', 'localhost', 'sakila')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>EXTRACTING THE UNIQUE FILM TITLES THAT EXIST WITHIN THE DATABASE</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def execute_query(query, engine):\r\n",
    "\r\n",
    "    return pd.read_sql_query(query, engine)\r\n",
    "\r\n",
    "query_film_titles = '''SELECT DISTINCT title FROM film'''\r\n",
    "\r\n",
    "unique_film_titles = execute_query(query_film_titles, sakila_engine)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>EXTRACTING THE FILMS THAT HAS BEEN RENTED IN AUGUST AND THE NUMBER OF TIMES THAT THIS EVENT HAS HAPPENED</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def films_rented_in_august(query, engine):\r\n",
    "\r\n",
    "    dataframe = execute_query(query, engine)\r\n",
    "    dataframe['rental_month'] = dataframe['rental_date'].dt.month\r\n",
    "    dataframe = dataframe[dataframe['rental_month'] == 8]\r\n",
    "    dataframe = dataframe.groupby('title').agg({'rental_month':len}).reset_index()\r\n",
    "    dataframe = dataframe.rename(columns = {'rental_month': 'rentals_august'})\r\n",
    "\r\n",
    "    return dataframe\r\n",
    "\r\n",
    "query_film_rentals = '''SELECT f.title, r.rental_date\r\n",
    "                        FROM film f JOIN inventory i USING(film_id)\r\n",
    "                        JOIN rental r ON i.inventory_id = r.inventory_id'''\r\n",
    "\r\n",
    "rentals_in_august_per_film = films_rented_in_august(query_film_rentals, sakila_engine)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>JOINING THE UNIQUE FILM TITLES WITH THE VALUE OF TIMES THAT EVERY TITLE WAS RENTED IN AUGUST - DEFINING THE TARGET COLUMN</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def map_films_rentals_august(dataframe_1, dataframe_2):\r\n",
    "\r\n",
    "    dataframe_1_dict = dataframe_1.set_index('title')['rentals_august'].to_dict()\r\n",
    "    dataframe_2['rentals_in_august'] = dataframe_2['title'].map(dataframe_1_dict)\r\n",
    "    dataframe_2['rentals_in_august'] = dataframe_2['rentals_in_august'].fillna(0)\r\n",
    "    \r\n",
    "    def rental_august(x):\r\n",
    "\r\n",
    "        if x > 0:\r\n",
    "            return 1\r\n",
    "        \r\n",
    "        else:\r\n",
    "            return 0\r\n",
    "\r\n",
    "    dataframe_2['rented_in_august'] = dataframe_2['rentals_in_august'].apply(rental_august)\r\n",
    "    dataframe_2 = dataframe_2.drop('rentals_in_august', axis = 1)\r\n",
    "\r\n",
    "    return dataframe_2\r\n",
    "\r\n",
    "rented_or_not_august = map_films_rentals_august(rentals_in_august_per_film, unique_film_titles)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>EXTRACTING THE FILM DATA AND MERGING THE DATA WITH THE RENTED IN AUGUST CONDITION</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "query_film_data = '''SELECT title, rental_duration, rental_rate, length, \r\n",
    "                     replacement_cost, rating, special_features\r\n",
    "                     FROM film'''\r\n",
    "\r\n",
    "films_data = execute_query(query_film_data, sakila_engine)\r\n",
    "film_data_target = pd.merge(films_data, rented_or_not_august)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>DROPPING THE TITLE COLUMN ONCE WE ALREADY HAVE THE DATA</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "film_data_target = film_data_target.drop('title', axis = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>FORMATTING THE SPECIAL FEATURES COLUMN BEFORE USING THE FEATURE</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def order_special_features(x):\r\n",
    "\r\n",
    "    return sorted(x, key = str.lower)\r\n",
    "\r\n",
    "film_data_target['special_features'] = film_data_target['special_features'].apply(order_special_features)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>MANUALLY ONE HOT ENCODING THE SPECIAL FEATURES COLUMN</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def one_hot_special_features(dataframe, column):\r\n",
    "\r\n",
    "    dataframe['behind_the_scenes'] = 0\r\n",
    "    dataframe['commentaries'] = 0\r\n",
    "    dataframe['deleted_scenes'] = 0\r\n",
    "    dataframe['trailers'] = 0\r\n",
    "\r\n",
    "    def behind_the_scenes(row):\r\n",
    "\r\n",
    "        if 'Behind the Scenes' in row[column]:\r\n",
    "            return 1\r\n",
    "\r\n",
    "        return 0\r\n",
    "\r\n",
    "    def commentaries(row):\r\n",
    "\r\n",
    "        if 'Commentaries' in row[column]:\r\n",
    "            return 1\r\n",
    "\r\n",
    "        return 0\r\n",
    "\r\n",
    "    def deleted_scenes(row):\r\n",
    "\r\n",
    "        if 'Deleted Scenes' in row[column]:\r\n",
    "            return 1\r\n",
    "\r\n",
    "        return 0\r\n",
    "\r\n",
    "    def trailers(row):\r\n",
    "\r\n",
    "        if 'Trailers' in row[column]:\r\n",
    "            return 1\r\n",
    "\r\n",
    "        return 0\r\n",
    "\r\n",
    "    dataframe['behind_the_scenes'] = film_data_target.apply(behind_the_scenes, axis = 1)\r\n",
    "    dataframe['commentaries'] = film_data_target.apply(commentaries, axis = 1) \r\n",
    "    dataframe['deleted_scenes'] = film_data_target.apply(deleted_scenes, axis = 1)\r\n",
    "    dataframe['trailers'] = film_data_target.apply(trailers, axis = 1)\r\n",
    "\r\n",
    "    dataframe = dataframe.drop(column, axis = 1)\r\n",
    "\r\n",
    "    return dataframe\r\n",
    "\r\n",
    "film_data_target = one_hot_special_features(film_data_target, 'special_features')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>CONVERTING THE RENTAL DURATION AND THE RENTAL RATE COLUMNS IN OBJECTS</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def numerical_to_categorical(dataframe, columns):\r\n",
    "\r\n",
    "    for column in columns:\r\n",
    "        dataframe[column] = dataframe[column].astype('object')\r\n",
    "\r\n",
    "    return dataframe\r\n",
    "\r\n",
    "film_data_target = numerical_to_categorical(film_data_target, ['rental_duration', 'rental_rate'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>PERFORMING THE X-Y SPLIT AND THE TRAIN TEST SPLIT</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def x_y_train_test(dataframe, target):\r\n",
    "\r\n",
    "    X = dataframe.drop(target, axis = 1)\r\n",
    "    y = dataframe[target]\r\n",
    "\r\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\r\n",
    "\r\n",
    "    return X_train, X_test, y_train, y_test\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = x_y_train_test(film_data_target, 'rented_in_august')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>SCALING THE NUMERICAL FEATURES</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def scaling(training_x, testing_x, columns):\r\n",
    "\r\n",
    "    training_x_numerical = training_x[columns]\r\n",
    "    testing_x_numerical = testing_x[columns]\r\n",
    "\r\n",
    "    scaler = StandardScaler().fit(training_x_numerical)\r\n",
    "\r\n",
    "    training_x_numerical_array = scaler.transform(training_x_numerical)\r\n",
    "    training_x_numerical_scaled = pd.DataFrame(data = training_x_numerical_array, columns = training_x_numerical.columns, index = training_x.index)\r\n",
    "\r\n",
    "    testing_x_numerical_array = scaler.transform(testing_x_numerical)\r\n",
    "    testing_x_numerical_scaled = pd.DataFrame(data = testing_x_numerical_array, columns = testing_x_numerical.columns, index = testing_x.index)\r\n",
    "\r\n",
    "    numerical_columns = training_x_numerical.columns.to_list()\r\n",
    "    training_x[numerical_columns] = training_x_numerical_scaled\r\n",
    "    testing_x[numerical_columns] = testing_x_numerical_scaled\r\n",
    "\r\n",
    "    return training_x, testing_x\r\n",
    "\r\n",
    "X_train_scaled, X_test_scaled = scaling(X_train, X_test, ['length', 'replacement_cost'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>ONE HOT ENCODING THE CATEGORICAL FEATURES</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def one_hot_encoding(training_x, testing_x, columns):\r\n",
    "\r\n",
    "    training_x_categorical = training_x[columns]\r\n",
    "    testing_x_categorical = testing_x[columns]\r\n",
    "\r\n",
    "    training_x = training_x.drop(columns, axis = 1)\r\n",
    "    testing_x = testing_x.drop(columns, axis = 1)\r\n",
    "\r\n",
    "    encoder = OneHotEncoder().fit(training_x_categorical)\r\n",
    "\r\n",
    "    total_columns = list()\r\n",
    "    columns_to_drop = list()\r\n",
    "\r\n",
    "    for columns in encoder.categories_:\r\n",
    "        columns_to_drop.append(columns[0])\r\n",
    "        for column in columns:\r\n",
    "            total_columns.append(column)\r\n",
    "\r\n",
    "    training_x_categorical_array = encoder.transform(training_x_categorical).toarray()\r\n",
    "    training_x_categorical_encoded = pd.DataFrame(data = training_x_categorical_array, columns = total_columns, index = training_x.index)\r\n",
    "    training_x_categorical_encoded = training_x_categorical_encoded.drop(columns_to_drop, axis = 1)\r\n",
    "\r\n",
    "    testing_x_categorical_array = encoder.transform(testing_x_categorical).toarray()\r\n",
    "    testing_x_categorical_encoded = pd.DataFrame(data = testing_x_categorical_array, columns = total_columns, index = testing_x.index)\r\n",
    "    testing_x_categorical_encoded = testing_x_categorical_encoded.drop(columns_to_drop, axis = 1)\r\n",
    "\r\n",
    "    training_x = pd.concat([training_x, training_x_categorical_encoded], axis = 1)\r\n",
    "    testing_x = pd.concat([testing_x, testing_x_categorical_encoded], axis = 1)\r\n",
    "\r\n",
    "    return training_x, testing_x\r\n",
    "\r\n",
    "X_train_scaled_encoded, X_test_scaled_encoded = one_hot_encoding(X_train_scaled, X_test_scaled, ['rental_duration', 'rental_rate', 'rating'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>OVER SAMPLING THE MINORITY CLASS OF THE TARGET FEATURE</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def over_sampling(training_x, training_y):\r\n",
    "\r\n",
    "    smote = SMOTE(random_state = 100, k_neighbors = 3)\r\n",
    "    X_train_scaled_SMOTE, y_train_SMOTE = smote.fit_resample(training_x, training_y)\r\n",
    "\r\n",
    "    return X_train_scaled_SMOTE, y_train_SMOTE    \r\n",
    "\r\n",
    "X_train_scaled_encoded_SMOTE, y_train_SMOTE = over_sampling(X_train_scaled_encoded, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>CREATING AND FITTING A LOGISTIC REGRESSION METHOD</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def create_fit_logistic_regression(training_x, training_y):\r\n",
    "\r\n",
    "    model = LogisticRegression()\r\n",
    "    model.fit(training_x, training_y)\r\n",
    "    \r\n",
    "    return model\r\n",
    "\r\n",
    "logistic_regression = create_fit_logistic_regression(X_train_scaled_encoded_SMOTE, y_train_SMOTE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>EXTRACTING THE METRICS OF THE MODEL</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def model_metrics(model, testing_x, testing_y):\r\n",
    "\r\n",
    "    predictions = model.predict(testing_x)\r\n",
    "\r\n",
    "    accuracy = accuracy_score(testing_y, predictions)\r\n",
    "    precision = precision_score(testing_y, predictions)\r\n",
    "    recall = recall_score(testing_y, predictions)\r\n",
    "    f1 = f1_score(testing_y, predictions)\r\n",
    "\r\n",
    "    return accuracy, precision, recall, f1\r\n",
    "\r\n",
    "model_accuracy, model_precision, model_recall, model_f1 = model_metrics(logistic_regression, X_test_scaled_encoded, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>EVALUATING THE METRICS OF THE MODEL</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "print('\\nLOGISTIC REGRESSION METRICS')\r\n",
    "print('---------------------------\\n')\r\n",
    "\r\n",
    "print(f'- Accuracy: {round(model_accuracy, 2)}')\r\n",
    "print(f'- Precision: {round(model_precision, 2)}')\r\n",
    "print(f'- Recall: {round(model_recall, 2)}')\r\n",
    "print(f'- F1: {round(model_f1, 2)}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "LOGISTIC REGRESSION METRICS\n",
      "---------------------------\n",
      "\n",
      "- Accuracy: 0.68\n",
      "- Precision: 0.96\n",
      "- Recall: 0.7\n",
      "- F1: 0.81\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('ironhack_environment': venv)"
  },
  "interpreter": {
   "hash": "df81bf56b2521791aaa0ff1ac8d57256f917b61d33ad24d6b6d13191d105bbf2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}